{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f14835",
   "metadata": {},
   "source": [
    "### ML PYspark\n",
    "\n",
    "The first thing to do is to create a .env file in the root of the directory. Add to the file the following two varibles \n",
    "ACCESS_KEY, ACCESS_SECRET. \n",
    "Check for more detailed explanation here: [dotenv](\"https://pypi.org/project/python-dotenv/), he explains how the .env should look like. After that, the variables are add to the os.environ and can be access as a simple dict structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94aa9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum as spark_sum, when, input_file_name\n",
    "from functools import reduce\n",
    "import sys\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "import os\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from dotenv import load_dotenv\n",
    "from sparkmeasure import StageMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c603316e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "## load .env\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94996dbf",
   "metadata": {},
   "source": [
    "## Console Login\n",
    "\n",
    "The following classes are to handle the spark on the AWS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fabe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.s3handler import Sparker, PreProcessing, FeatureEngineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4e426f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host-006.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Local Session my friend</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1200ff390>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Initialize the class\n",
    "spark = Sparker(os.environ['ACCESS_KEY'],os.environ['ACCESS_SECRET'])\n",
    "\n",
    "## local session\n",
    "session = spark._create_local_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6cabcc",
   "metadata": {},
   "source": [
    "## Read parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a4c2aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: ['s3a://ubs-datasets/FRACTAL/data/train/TRAIN-0436_6399-002955400.parquet']\n"
     ]
    }
   ],
   "source": [
    "parquet_cols = [\"xyz\",\"Intensity\",\"Classification\",\"Red\",\"Green\",\"Blue\",\"Infrared\",\"ReturnNumber\",\"NumberOfReturns\"]\n",
    "\n",
    "## Read the parquet and stored it \n",
    "df = spark.read_parquet(\"ubs-datasets\",\n",
    "                    \"FRACTAL/data/train/TRAIN-0436_6399-002955400.parquet\",\n",
    "                    read_all=False) \\\n",
    "                    .select(*parquet_cols)\n",
    "\n",
    "# # Read the list of parquet files\n",
    "# list_s3 = [\"FRACTAL/data/train/TRAIN-1200_6136-008972557.parquet\", \"FRACTAL/data/train/TRAIN-0436_6399-002955400.parquet\"]\n",
    "# df = spark.read_parquet(\"ubs-datasets\",\n",
    "#                     list_s3,\n",
    "#                     read_all=False) \\\n",
    "#                     .select(*parquet_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d6323bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- xyz: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- Intensity: integer (nullable = true)\n",
      " |-- Classification: short (nullable = true)\n",
      " |-- Red: integer (nullable = true)\n",
      " |-- Green: integer (nullable = true)\n",
      " |-- Blue: integer (nullable = true)\n",
      " |-- Infrared: integer (nullable = true)\n",
      " |-- ReturnNumber: short (nullable = true)\n",
      " |-- NumberOfReturns: short (nullable = true)\n",
      "\n",
      "Number of rows: 90090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 90090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "print(f\"Number of rows: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f5af63",
   "metadata": {},
   "source": [
    "## Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86af3b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xyz',\n",
       " 'Intensity',\n",
       " 'Classification',\n",
       " 'Red',\n",
       " 'Green',\n",
       " 'Blue',\n",
       " 'Infrared',\n",
       " 'ReturnNumber',\n",
       " 'NumberOfReturns']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c98705d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = PreProcessing(df)\n",
    "df = preprocessing.split_xyz()\n",
    "\n",
    "# ## feature engineering\n",
    "engfeature = FeatureEngineering(df)\n",
    "df = engfeature.apply_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfdaefa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Intensity',\n",
       " 'Classification',\n",
       " 'Red',\n",
       " 'Green',\n",
       " 'Blue',\n",
       " 'Infrared',\n",
       " 'ReturnNumber',\n",
       " 'NumberOfReturns',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'height_above_ground',\n",
       " 'local_density',\n",
       " 'local_z_std',\n",
       " 'local_z_range',\n",
       " 'roughness',\n",
       " 'return_ratio',\n",
       " 'is_single_return',\n",
       " 'is_last_return',\n",
       " 'ndvi',\n",
       " 'green_red_ratio',\n",
       " 'ndwi']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2076c2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---+-----+----+--------+------------+---------------+---+---+---+-------------------+-------------+-----------+-------------+---------+------------+----------------+--------------+----+---------------+----+\n",
      "|Intensity|Classification|Red|Green|Blue|Infrared|ReturnNumber|NumberOfReturns|  x|  y|  z|height_above_ground|local_density|local_z_std|local_z_range|roughness|return_ratio|is_single_return|is_last_return|ndvi|green_red_ratio|ndwi|\n",
      "+---------+--------------+---+-----+----+--------+------------+---------------+---+---+---+-------------------+-------------+-----------+-------------+---------+------------+----------------+--------------+----+---------------+----+\n",
      "|        0|             0|  0|    0|   0|       0|           0|              0|  0|  0|  0|                  0|            0|          0|            0|        0|           0|               0|             0|   0|              0|   0|\n",
      "+---------+--------------+---+-----+----+--------+------------+---------------+---+---+---+-------------------+-------------+-----------+-------------+---------+------------+----------------+--------------+----+---------------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum\n",
    "feature_cols = df.columns\n",
    "null_counts = df.select([\n",
    "    _sum(col(c).isNull().cast(\"int\")).alias(c) \n",
    "    for c in feature_cols\n",
    "])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15267702",
   "metadata": {},
   "source": [
    "### Load | Models\n",
    "Prepare the variable for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b333a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import taskmetrics to see how the model is performing\n",
    "stagemetrics = StageMetrics(spark.spark)\n",
    "stagemetrics.begin() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fdd08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df.drop(\"Classification\").columns  \n",
    "assembler = VectorAssembler(inputCols=feature_cols,\n",
    "                            outputCol=\"features\",\n",
    "                           # handleInvalid=\"skip\" \n",
    "                           ) \n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42ce6103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define model\n",
    "rf = RandomForestClassifier(featuresCol=\"scaled_features\", \n",
    "                            labelCol=\"Classification\",\n",
    "                            bootstrap=True, \n",
    "                            numTrees=60,\n",
    "                            maxDepth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1e75cd",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c2554b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler, scaler, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b11c78",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab1db101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd0a7c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 86:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----+-----+-----+--------+------------+---------------+----------+-----------+------+--------------------+-------------+-------------------+-----------------+-------------------+------------+----------------+--------------+-------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Intensity|Classification|  Red|Green| Blue|Infrared|ReturnNumber|NumberOfReturns|         x|          y|     z| height_above_ground|local_density|        local_z_std|    local_z_range|          roughness|return_ratio|is_single_return|is_last_return|               ndvi|   green_red_ratio|              ndwi|            features|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+---------+--------------+-----+-----+-----+--------+------------+---------------+----------+-----------+------+--------------------+-------------+-------------------+-----------------+-------------------+------------+----------------+--------------+-------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|     2744|             2|24064|23296|27136|    5120|           1|              1|436950.005| 6398458.04|14.301|0.045999999999999375|          113|0.03123873248196348|0.136000000000001|0.21396392110933743|         1.0|               1|             1|-0.6491227847751239|0.9680850661533799|0.6396396171297996|[2744.0,24064.0,2...|[3.02192436232154...|[0.0,0.0343717097...|[0.0,5.7286182959...|       2.0|\n",
      "|     1771|             2|24064|23296|27136|    6144|           1|              1|436950.303|6398458.129|14.337| 0.08199999999999896|          113|0.03123873248196348|0.136000000000001|0.21396392110933743|         1.0|               1|             1| -0.593220319345196|0.9680850661533799| 0.582608675862477|[1771.0,24064.0,2...|[1.95037465221263...|[0.0,0.0343717097...|[0.0,5.7286182959...|       2.0|\n",
      "+---------+--------------+-----+-----+-----+--------+------------+---------------+----------+-----------+------+--------------------+-------------+-------------------+-----------------+-------------------+------------+----------------+--------------+-------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model.transform(df).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6859a1",
   "metadata": {},
   "source": [
    "## Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "066c66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf646b7",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42fd6bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: ['s3a://ubs-datasets/FRACTAL/data/train/TRAIN-1200_6136-008972557.parquet']\n"
     ]
    }
   ],
   "source": [
    "df_test = spark.read_parquet(\"ubs-datasets\",\n",
    "                    \"FRACTAL/data/train/TRAIN-1200_6136-008972557.parquet\",\n",
    "                    read_all=False) \\\n",
    "                    .select(*parquet_cols)\n",
    "\n",
    "preprocessing = PreProcessing(df_test)\n",
    "df_test = preprocessing.split_xyz()\n",
    "eng_feature = FeatureEngineering(df_test)\n",
    "df_test = eng_feature.apply_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "592a37f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 93:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------------+\n",
      "|Classification|Prediction|         Probability|\n",
      "+--------------+----------+--------------------+\n",
      "|             4|       5.0|[0.0,5.6102743770...|\n",
      "|             4|       5.0|[0.0,5.4542493826...|\n",
      "+--------------+----------+--------------------+\n",
      "only showing top 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(df_test)\n",
    "model.transform(df_test).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6077e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----+-----+-----+--------+------------+---------------+----------+----------+------------------+-------------------+-------------+-----------------+------------------+-------------------+------------+----------------+--------------+-------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Intensity|Classification|  Red|Green| Blue|Infrared|ReturnNumber|NumberOfReturns|         x|         y|                 z|height_above_ground|local_density|      local_z_std|     local_z_range|          roughness|return_ratio|is_single_return|is_last_return|               ndvi|   green_red_ratio|                ndwi|            features|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+---------+--------------+-----+-----+-----+--------+------------+---------------+----------+----------+------------------+-------------------+-------------+-----------------+------------------+-------------------+------------+----------------+--------------+-------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|      805|             4|21248|23040|19712|   32256|           1|              2|1200801.71|6135351.96|1194.8500000000001|  4.810000000000173|          506|8.535863902598672|22.680000000000064|0.37619497146754727|         0.5|               0|             0|0.20574162294890808|1.0843372983651498|-0.16666666365258495|[805.0,21248.0,23...|[0.88653393282392...|[0.0,0.0336616462...|[0.0,5.6102743770...|       5.0|\n",
      "|      821|             4|21248|23040|19712|   37632|           4|              4| 1200801.8|6135351.73|           1194.84| 4.7999999999999545|          506|8.535863902598672|22.680000000000064|0.37619497146754727|         1.0|               0|             1|0.27826086483931955|1.0843372983651498|-0.24050632514988257|[821.0,21248.0,23...|[0.90415448304154...|[0.0,0.0327254962...|[0.0,5.4542493826...|       5.0|\n",
      "+---------+--------------+-----+-----+-----+--------+------------+---------------+----------+----------+------------------+-------------------+-------------+-----------------+------------------+-------------------+------------+----------------+--------------+-------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model.transform(df_test).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e5fda5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5bc03448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7542c8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 110:>                                                        (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol = 'Classification',\n",
    "    predictionCol = 'Prediction',\n",
    "    metricName = 'accuracy'\n",
    ")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy = {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dced8672",
   "metadata": {},
   "outputs": [],
   "source": [
    "stagemetrics.end()\n",
    "# stagemetrics.print_memory_report()\n",
    "# stagemetrics.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c539fd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Additional stage-level executor metrics (memory usage info updated at each heartbeat):\n",
      "\n",
      "Stage 14 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 14 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 16 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 16 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 19 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 19 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 23 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 23 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 24 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 24 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 26 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 26 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 27 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 27 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 29 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 29 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 30 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 30 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 32 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 32 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 35 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 35 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 38 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 38 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 41 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 41 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 42 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 42 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 45 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 45 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 46 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 46 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 49 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 49 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 50 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 50 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 53 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 53 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 54 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 54 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 57 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 57 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 58 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 58 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 61 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 61 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 62 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 62 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 65 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 65 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 66 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 66 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 69 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 69 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 70 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 70 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 73 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 73 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 74 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 74 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 77 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 77 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 78 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 78 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 81 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 81 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 82 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 82 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 83 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 83 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 85 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 85 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 86 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 86 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "No executor metrics available for stage 88 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 88 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 91 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 91 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 92 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 92 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 93 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 93 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 95 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 95 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 98 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 98 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 99 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 99 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 101 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 101 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 104 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 104 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 105 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 105 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 107 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 107 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 110 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 110 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 111 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 111 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(str(stagemetrics.print_memory_report())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f71000aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spark session stopped.\n"
     ]
    }
   ],
   "source": [
    "spark.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc4304cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b588f4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-fractal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
