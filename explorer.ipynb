{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f14835",
   "metadata": {},
   "source": [
    "### ML PYspark\n",
    "\n",
    "The first thing to do is to create a .env file in the root of the directory. Add to the file the following two varibles \n",
    "ACCESS_KEY, ACCESS_SECRET. \n",
    "Check for more detailed explanation here: [dotenv](\"https://pypi.org/project/python-dotenv/), he explains how the .env should look like. After that, the variables are add to the os.environ and can be access as a simple dict structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94aa9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum as spark_sum, when, input_file_name\n",
    "from functools import reduce\n",
    "import sys\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "import os\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from dotenv import load_dotenv\n",
    "from sparkmeasure import StageMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c603316e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "## load .env\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94996dbf",
   "metadata": {},
   "source": [
    "## Console Login\n",
    "\n",
    "The following classes are to handle the spark on the AWS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fabe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.s3handler import Sparker, PreProcessing, FeatureEngineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4e426f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host-006.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Local Session my friend</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1200ff390>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Initialize the class\n",
    "spark = Sparker(os.environ['ACCESS_KEY'],os.environ['ACCESS_SECRET'])\n",
    "\n",
    "## local session\n",
    "session = spark._create_local_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6cabcc",
   "metadata": {},
   "source": [
    "## Read parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a4c2aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: ['s3a://ubs-datasets/FRACTAL/data/train/TRAIN-0436_6399-002955400.parquet']\n"
     ]
    }
   ],
   "source": [
    "parquet_cols = [\"xyz\",\"Intensity\",\"Classification\",\"Red\",\"Green\",\"Blue\",\"Infrared\",\"ReturnNumber\",\"NumberOfReturns\"]\n",
    "\n",
    "## Read the parquet and stored it \n",
    "df = spark.read_parquet(\"ubs-datasets\",\n",
    "                    \"FRACTAL/data/train/TRAIN-0436_6399-002955400.parquet\",\n",
    "                    read_all=False) \\\n",
    "                    .select(*parquet_cols)\n",
    "\n",
    "# # Read the list of parquet files\n",
    "# list_s3 = [\"FRACTAL/data/train/TRAIN-1200_6136-008972557.parquet\", \"FRACTAL/data/train/TRAIN-0436_6399-002955400.parquet\"]\n",
    "# df = spark.read_parquet(\"ubs-datasets\",\n",
    "#                     list_s3,\n",
    "#                     read_all=False) \\\n",
    "#                     .select(*parquet_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d6323bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- xyz: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- Intensity: integer (nullable = true)\n",
      " |-- Classification: short (nullable = true)\n",
      " |-- Red: integer (nullable = true)\n",
      " |-- Green: integer (nullable = true)\n",
      " |-- Blue: integer (nullable = true)\n",
      " |-- Infrared: integer (nullable = true)\n",
      " |-- ReturnNumber: short (nullable = true)\n",
      " |-- NumberOfReturns: short (nullable = true)\n",
      "\n",
      "Number of rows: 90090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 90090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "print(f\"Number of rows: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f5af63",
   "metadata": {},
   "source": [
    "## Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86af3b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xyz',\n",
       " 'Intensity',\n",
       " 'Classification',\n",
       " 'Red',\n",
       " 'Green',\n",
       " 'Blue',\n",
       " 'Infrared',\n",
       " 'ReturnNumber',\n",
       " 'NumberOfReturns']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c98705d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = PreProcessing(df)\n",
    "df = preprocessing.split_xyz()\n",
    "\n",
    "# ## feature engineering\n",
    "engfeature = FeatureEngineering(df)\n",
    "df = engfeature.apply_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfdaefa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Intensity',\n",
       " 'Classification',\n",
       " 'Red',\n",
       " 'Green',\n",
       " 'Blue',\n",
       " 'Infrared',\n",
       " 'ReturnNumber',\n",
       " 'NumberOfReturns',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'height_above_ground',\n",
       " 'local_density',\n",
       " 'local_z_std',\n",
       " 'local_z_range',\n",
       " 'roughness',\n",
       " 'return_ratio',\n",
       " 'is_single_return',\n",
       " 'is_last_return',\n",
       " 'ndvi',\n",
       " 'green_red_ratio',\n",
       " 'ndwi']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2076c2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---+-----+----+--------+------------+---------------+---+---+---+-------------------+-------------+-----------+-------------+---------+------------+----------------+--------------+----+---------------+----+\n",
      "|Intensity|Classification|Red|Green|Blue|Infrared|ReturnNumber|NumberOfReturns|  x|  y|  z|height_above_ground|local_density|local_z_std|local_z_range|roughness|return_ratio|is_single_return|is_last_return|ndvi|green_red_ratio|ndwi|\n",
      "+---------+--------------+---+-----+----+--------+------------+---------------+---+---+---+-------------------+-------------+-----------+-------------+---------+------------+----------------+--------------+----+---------------+----+\n",
      "|        0|             0|  0|    0|   0|       0|           0|              0|  0|  0|  0|                  0|            0|          0|            0|        0|           0|               0|             0|   0|              0|   0|\n",
      "+---------+--------------+---+-----+----+--------+------------+---------------+---+---+---+-------------------+-------------+-----------+-------------+---------+------------+----------------+--------------+----+---------------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum\n",
    "feature_cols = df.columns\n",
    "null_counts = df.select([\n",
    "    _sum(col(c).isNull().cast(\"int\")).alias(c) \n",
    "    for c in feature_cols\n",
    "])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15267702",
   "metadata": {},
   "source": [
    "### Load | Models\n",
    "Prepare the variable for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b333a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import taskmetrics to see how the model is performing\n",
    "stagemetrics = StageMetrics(spark.spark)\n",
    "stagemetrics.begin() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fdd08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df.drop(\"Classification\").columns  \n",
    "assembler = VectorAssembler(inputCols=feature_cols,\n",
    "                            outputCol=\"features\",\n",
    "                           # handleInvalid=\"skip\" \n",
    "                           ) \n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42ce6103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define model\n",
    "rf = RandomForestClassifier(featuresCol=\"scaled_features\", \n",
    "                            labelCol=\"Classification\",\n",
    "                            bootstrap=True, \n",
    "                            numTrees=60,\n",
    "                            maxDepth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1e75cd",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c2554b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler, scaler, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b11c78",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab1db101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd0a7c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 86:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----+-----+-----+--------+------------+---------------+----------+-----------+------+--------------------+-------------+-------------------+-----------------+-------------------+------------+----------------+--------------+-------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Intensity|Classification|  Red|Green| Blue|Infrared|ReturnNumber|NumberOfReturns|         x|          y|     z| height_above_ground|local_density|        local_z_std|    local_z_range|          roughness|return_ratio|is_single_return|is_last_return|               ndvi|   green_red_ratio|              ndwi|            features|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+---------+--------------+-----+-----+-----+--------+------------+---------------+----------+-----------+------+--------------------+-------------+-------------------+-----------------+-------------------+------------+----------------+--------------+-------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|     2744|             2|24064|23296|27136|    5120|           1|              1|436950.005| 6398458.04|14.301|0.045999999999999375|          113|0.03123873248196348|0.136000000000001|0.21396392110933743|         1.0|               1|             1|-0.6491227847751239|0.9680850661533799|0.6396396171297996|[2744.0,24064.0,2...|[3.02192436232154...|[0.0,0.0343717097...|[0.0,5.7286182959...|       2.0|\n",
      "|     1771|             2|24064|23296|27136|    6144|           1|              1|436950.303|6398458.129|14.337| 0.08199999999999896|          113|0.03123873248196348|0.136000000000001|0.21396392110933743|         1.0|               1|             1| -0.593220319345196|0.9680850661533799| 0.582608675862477|[1771.0,24064.0,2...|[1.95037465221263...|[0.0,0.0343717097...|[0.0,5.7286182959...|       2.0|\n",
      "+---------+--------------+-----+-----+-----+--------+------------+---------------+----------+-----------+------+--------------------+-------------+-------------------+-----------------+-------------------+------------+----------------+--------------+-------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model.transform(df).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6859a1",
   "metadata": {},
   "source": [
    "## Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "066c66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf646b7",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42fd6bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: ['s3a://ubs-datasets/FRACTAL/data/train/TRAIN-1200_6136-008972557.parquet']\n"
     ]
    }
   ],
   "source": [
    "df_test = spark.read_parquet(\"ubs-datasets\",\n",
    "                    \"FRACTAL/data/train/TRAIN-1200_6136-008972557.parquet\",\n",
    "                    read_all=False) \\\n",
    "                    .select(*parquet_cols)\n",
    "\n",
    "preprocessing = PreProcessing(df_test)\n",
    "df_test = preprocessing.split_xyz()\n",
    "eng_feature = FeatureEngineering(df_test)\n",
    "df_test = eng_feature.apply_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "592a37f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 93:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------------+\n",
      "|Classification|Prediction|         Probability|\n",
      "+--------------+----------+--------------------+\n",
      "|             4|       5.0|[0.0,5.6102743770...|\n",
      "|             4|       5.0|[0.0,5.4542493826...|\n",
      "+--------------+----------+--------------------+\n",
      "only showing top 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(df_test)\n",
    "model.transform(df_test).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6077e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----+-----+-----+--------+------------+---------------+----------+----------+------------------+-------------------+-------------+-----------------+------------------+-------------------+------------+----------------+--------------+-------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Intensity|Classification|  Red|Green| Blue|Infrared|ReturnNumber|NumberOfReturns|         x|         y|                 z|height_above_ground|local_density|      local_z_std|     local_z_range|          roughness|return_ratio|is_single_return|is_last_return|               ndvi|   green_red_ratio|                ndwi|            features|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+---------+--------------+-----+-----+-----+--------+------------+---------------+----------+----------+------------------+-------------------+-------------+-----------------+------------------+-------------------+------------+----------------+--------------+-------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|      805|             4|21248|23040|19712|   32256|           1|              2|1200801.71|6135351.96|1194.8500000000001|  4.810000000000173|          506|8.535863902598672|22.680000000000064|0.37619497146754727|         0.5|               0|             0|0.20574162294890808|1.0843372983651498|-0.16666666365258495|[805.0,21248.0,23...|[0.88653393282392...|[0.0,0.0336616462...|[0.0,5.6102743770...|       5.0|\n",
      "|      821|             4|21248|23040|19712|   37632|           4|              4| 1200801.8|6135351.73|           1194.84| 4.7999999999999545|          506|8.535863902598672|22.680000000000064|0.37619497146754727|         1.0|               0|             1|0.27826086483931955|1.0843372983651498|-0.24050632514988257|[821.0,21248.0,23...|[0.90415448304154...|[0.0,0.0327254962...|[0.0,5.4542493826...|       5.0|\n",
      "+---------+--------------+-----+-----+-----+--------+------------+---------------+----------+----------+------------------+-------------------+-------------+-----------------+------------------+-------------------+------------+----------------+--------------+-------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model.transform(df_test).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e5fda5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5bc03448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7542c8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 110:>                                                        (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol = 'Classification',\n",
    "    predictionCol = 'Prediction',\n",
    "    metricName = 'accuracy'\n",
    ")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy = {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dced8672",
   "metadata": {},
   "outputs": [],
   "source": [
    "stagemetrics.end()\n",
    "# stagemetrics.print_memory_report()\n",
    "# stagemetrics.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c539fd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Additional stage-level executor metrics (memory usage info updated at each heartbeat):\n",
      "\n",
      "Stage 14 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 14 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 16 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 16 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 19 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 19 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 23 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 23 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 24 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 24 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 26 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 26 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 27 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 27 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 29 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 29 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 30 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 30 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 32 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 32 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 35 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 35 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 38 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 38 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 41 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 41 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 42 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 42 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 45 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 45 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 46 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 46 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 49 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 49 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 50 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 50 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 53 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 53 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 54 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 54 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 57 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 57 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 58 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 58 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 61 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 61 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 62 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 62 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 65 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 65 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 66 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 66 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 69 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 69 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 70 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 70 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 73 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 73 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 74 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 74 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 77 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 77 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 78 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 78 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 81 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 81 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 82 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 82 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 83 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 83 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 85 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 85 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "Stage 86 JVMHeapMemory maxVal bytes => 446825352 (426.1 MB)\n",
      "Stage 86 OnHeapExecutionMemory maxVal bytes => 0 (0 Bytes)\n",
      "No executor metrics available for stage 88 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 88 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 91 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 91 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 92 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 92 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 93 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 93 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 95 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 95 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 98 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 98 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 99 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 99 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 101 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 101 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 104 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 104 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 105 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 105 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 107 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 107 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 110 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 110 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 111 and metric JVMHeapMemory. Please retry after a few seconds.\n",
      "No executor metrics available for stage 111 and metric OnHeapExecutionMemory. Please retry after a few seconds.\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(str(stagemetrics.print_memory_report())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f71000aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spark session stopped.\n"
     ]
    }
   ],
   "source": [
    "spark.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc4304cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7708176",
   "metadata": {},
   "source": [
    "## Read txt \n",
    "\n",
    "aquele que a bea nao gosta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b588f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"/mnt/d/desktop/COPERNICUS/Classes/3-semester/bigdata/list_files/train_files.txt\"\n",
    "path_test = \"/mnt/d/desktop/COPERNICUS/Classes/3-semester/bigdata/list_files/test_files.txt\"\n",
    "path_val = \"/mnt/d/desktop/COPERNICUS/Classes/3-semester/bigdata/list_files/val_files.txt\"\n",
    "with open(path_train, 'r')  as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "with open(path_test, 'r')  as file:\n",
    "    lines_test = file.readlines()\n",
    "\n",
    "with open(path_val, 'r')  as file:\n",
    "    lines_val = file.readlines()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a320910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_file_names(lines, percentage = None):\n",
    "    \"\"\"\n",
    "    Match .parquet and return a list. If percentage, then return the sampled list.\n",
    "    \n",
    "    Args:\n",
    "        lines: List containing files name.\n",
    "    Percentage: float 0-1\n",
    "        The percentage of the total files\n",
    "    \"\"\"\n",
    "    import re \n",
    "    from random import sample\n",
    "    final_list =[]\n",
    "    for l in lines:\n",
    "        split =  l.split()\n",
    "        if len(split)>=1:\n",
    "            filename = split[-1]\n",
    "        match = re.search(r'([A-Z0-9_-]+.parquet)', filename)\n",
    "        if match:\n",
    "            final_list.append(filename)\n",
    "    \n",
    "    if percentage is not None:\n",
    "        if percentage >= 1.0:\n",
    "            raise ValueError(\"Percentage should be a float value between 0 and 1.\")\n",
    "        total_num = len(final_list)\n",
    "        perc = int(percentage*total_num)\n",
    "        return sample(final_list, k=perc)\n",
    "    \n",
    "    else: \n",
    "        return final_list   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "13c52976",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train = retrieve_file_names(lines, percentage=0.0001)\n",
    "list_test = retrieve_file_names(lines_test, percentage=0.0001)\n",
    "list_val = retrieve_file_names(lines_val, percentage=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "50b3dbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 8 \n",
      " Test : 1 \n",
      " Val 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {len(list_train)} \\n Test : {len(list_test)} \\n Val {len(list_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c61bb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRAIN-0935_6309-007770476.parquet',\n",
       " 'TRAIN-1185_6099-009163042.parquet',\n",
       " 'TRAIN-0736_6275-006984865.parquet',\n",
       " 'TRAIN-0903_6366-000044086.parquet',\n",
       " 'TRAIN-0747_6275-006666552.parquet',\n",
       " 'TRAIN-0970_6345-001579788.parquet',\n",
       " 'TRAIN-0460_6425-002963500.parquet',\n",
       " 'TRAIN-1193_6107-008949591.parquet']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a784aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train/TRAIN-0935_6309-007770476.parquet',\n",
       " 'train/TRAIN-1185_6099-009163042.parquet',\n",
       " 'train/TRAIN-0736_6275-006984865.parquet',\n",
       " 'train/TRAIN-0903_6366-000044086.parquet',\n",
       " 'train/TRAIN-0747_6275-006666552.parquet',\n",
       " 'train/TRAIN-0970_6345-001579788.parquet',\n",
       " 'train/TRAIN-0460_6425-002963500.parquet',\n",
       " 'train/TRAIN-1193_6107-008949591.parquet']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"train/{file}\" for file in list_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a9e2faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train/TRAIN-0935_6309-007770476.parquet'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"train/{list_train[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "78c51e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0a7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e802e9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m sample(population, k, *, counts=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Chooses k unique random elements from a population sequence.\n",
      "\n",
      "Returns a new list containing elements from the population while\n",
      "leaving the original population unchanged.  The resulting list is\n",
      "in selection order so that all sub-slices will also be valid random\n",
      "samples.  This allows raffle winners (the sample) to be partitioned\n",
      "into grand prize and second place winners (the subslices).\n",
      "\n",
      "Members of the population need not be hashable or unique.  If the\n",
      "population contains repeats, then each occurrence is a possible\n",
      "selection in the sample.\n",
      "\n",
      "Repeated elements can be specified one at a time or with the optional\n",
      "counts parameter.  For example:\n",
      "\n",
      "    sample(['red', 'blue'], counts=[4, 2], k=5)\n",
      "\n",
      "is equivalent to:\n",
      "\n",
      "    sample(['red', 'red', 'red', 'red', 'blue', 'blue'], k=5)\n",
      "\n",
      "To choose a sample from a range of integers, use range() for the\n",
      "population argument.  This is especially fast and space efficient\n",
      "for sampling from a large population:\n",
      "\n",
      "    sample(range(10000000), 60)\n",
      "\u001b[31mFile:\u001b[39m      ~/.local/share/uv/python/cpython-3.13.7-linux-x86_64-gnu/lib/python3.13/random.py\n",
      "\u001b[31mType:\u001b[39m      method"
     ]
    }
   ],
   "source": [
    "?sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e5d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
